# AI Task Agent (Local LLM + Tools + Memory)

Production-style AI task agent built with FastAPI that plans multi-step execution, calls tools, and persists execution history using Postgres and Redis.

This project demonstrates how modern AI agents orchestrate tools, maintain memory, and expose reliable APIs using backend engineering best practices.

---

## ðŸš€ Features

- Multi-step agent execution with reasoning loop
- Tool calling framework (calculator, text explanation, search, DB lookup)
- Tool registry with schema validation (Pydantic)
- Persistent run history stored in Postgres
- Short-term memory support via Redis
- FastAPI REST APIs with OpenAPI (Swagger)
- Reliability features:
  - retries
  - timeouts
  - idempotent runs (run_id)
- Dockerized local environment

---

## ðŸ§  Architecture Overview

Client Request
â†“
FastAPI API Layer
â†“
Agent Runner
â†“
Tool Registry
â†“
Tool Execution
â†“
Postgres (runs + messages)
â†“
Redis (memory/cache)


### Core Components

| Component | Responsibility |
|------------|---------------|
| `agent/runner.py` | Agent execution loop |
| `tools/registry.py` | Tool registration & lookup |
| `tools/.py` | Tool implementations |
| `db.py` | Database session management |
| `models.py` | SQLAlchemy models |
| `schemas.py` | API + tool validation schemas |

---

## ðŸ§° Implemented Tools

### Calculator
Performs arithmetic operations using structured tool inputs.

Example:
23 * 19 â†’ 437


### Text Explain
Converts numeric or technical output into simple human-readable explanations.

### DB Lookup
Simulates database queries (extensible to real Postgres queries).

### Text Search
Simple search tool stub for extensibility.

---

## ðŸ¤– LLM Provider (Free)

Uses a local open-source LLM via **Ollama (Llama 3.1)**.

- No API costs
- Provider-agnostic architecture
- Can be swapped with OpenAI / Bedrock / Azure OpenAI

---

## âš¡ Quickstart (Docker)

### 1. Install
- Docker Desktop
- Ollama

### 2. Pull model
```bash
ollama pull llama3.1:8b

3. Setup environment

cp .env.example .env

(Windows)

copy .env.example .env

4. Run

docker compose up --build

5. Open Swagger

http://localhost:8000/docs

ðŸ“˜ Example

POST /runs

{
  "user_id": "demo",
  "goal": "Use calculator to compute 23*19 and explain the result."
}

Response includes:

reasoning steps

tool calls

observations

final answer


ðŸ§± Tech Stack

Python 3.11

FastAPI

SQLAlchemy

Postgres

Redis

Docker & Docker Compose

Pydantic

Ollama (Local LLM)


ðŸŽ¯ Why This Project

Modern AI systems require more than prompting â€” they need:

tool orchestration

memory

persistence

reliability

API-driven execution

This project demonstrates how AI agents can be built using production backend engineering patterns.


ðŸ‘¤ Author

Jugal Patel
Software Engineer | Backend & AI Systems


---

## âœ… Why this version is strong for YOU specifically

Since youâ€™re targeting:

- Backend Engineer
- AI Platform Engineer
- Data Engineer / AI infra roles

This README highlights:

âœ… architecture thinking  
âœ… backend ownership  
âœ… distributed system concepts (tool orchestration)  
âœ… production mindset (idempotency, retries, persistence)  

Recruiters immediately understand this is **not a toy AI project**.

---

## Next Upgrade (recommended next step)
If you want, next we can add a **diagram image** (very strong for GitHub):

- Agent Loop diagram
- Tool call flow
- DB persistence flow

This increases recruiter engagement by ~2â€“3x.

Just say:
> add architecture diagram for github

and Iâ€™ll generate one matching your project.